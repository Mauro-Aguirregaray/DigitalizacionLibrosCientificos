{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c122e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ruta absoluta a la carpeta src\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from utils_TATR import outputs_to_objects, build_grid_with_spans, fill_grid_with_ocr, fill_grid_from_global_ocr_centered, draw_tatr_overlays_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702e32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\TesisOCR_TATR\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "from torchvision import transforms  # 👈 aquí está 'transforms'\n",
    "\n",
    "#from tatr_ocr.transforms_tatr import make_structure_transform, to_model_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a65a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "cropped_table = Image.open(\"tabla.jpg\").convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "714d4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MaxResize:\n",
    "    \"\"\"\n",
    "    Redimensiona una imagen manteniendo aspecto para que el lado mayor sea `max_size`.\n",
    "    A diferencia de la versión \"segura\", esta implementación **también hace upscaling**\n",
    "    si la imagen es más chica que `max_size`.\n",
    "\n",
    "    Args:\n",
    "        max_size (int): Tamaño máximo del lado mayor (la imagen resultante siempre tendrá\n",
    "            su lado mayor igual a este valor).\n",
    "        resample (int): Filtro de remuestreo de PIL (por defecto Image.BILINEAR).\n",
    "\n",
    "    Returns:\n",
    "        Image.Image: Imagen redimensionada con el nuevo tamaño.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: Si la entrada no es una instancia de PIL.Image.Image.\n",
    "        ValueError: Si la imagen tiene dimensiones inválidas (<= 0).\n",
    "\n",
    "    Examples:\n",
    "        >>> img = Image.open(\"ejemplo.jpg\")\n",
    "        >>> transform = MaxResize(max_size=800)\n",
    "        >>> out = transform(img)\n",
    "        >>> out.size\n",
    "        (800, 533)  # si la original era 1200x800\n",
    "    \"\"\"\n",
    "    max_size: int = 800\n",
    "    resample: int = Image.BILINEAR\n",
    "\n",
    "    def __call__(self, image: Image.Image) -> Image.Image:\n",
    "        if not isinstance(image, Image.Image):\n",
    "            raise TypeError(f\"Se esperaba PIL.Image.Image, recibido: {type(image)}\")\n",
    "\n",
    "        width, height = image.size\n",
    "        if width <= 0 or height <= 0:\n",
    "            raise ValueError(f\"Tamaño de imagen inválido: {image.size}\")\n",
    "\n",
    "        current_max = max(width, height)\n",
    "        scale = self.max_size / float(current_max)\n",
    "        new_w = max(1, int(round(scale * width)))\n",
    "        new_h = max(1, int(round(scale * height)))\n",
    "\n",
    "        return image.resize((new_w, new_h), resample=self.resample)\n",
    "\n",
    "\n",
    "def make_structure_transform(\n",
    "    max_size: int = 1000,\n",
    "    mean: Sequence[float] = (0.485, 0.456, 0.406),\n",
    "    std: Sequence[float] = (0.229, 0.224, 0.225),\n",
    "):\n",
    "    \"\"\"\n",
    "    Construye un pipeline `transforms.Compose` para preparar imágenes de estructura/tablas.\n",
    "\n",
    "    El pipeline incluye:\n",
    "    - MaxResize: asegura que el lado mayor quede exactamente en `max_size`.\n",
    "    - ToTensor: convierte a tensor (C,H,W) en [0,1].\n",
    "    - Normalize: normaliza con `mean` y `std` (por defecto, ImageNet).\n",
    "\n",
    "    Args:\n",
    "        max_size (int): Tamaño máximo del lado mayor tras redimensionar.\n",
    "        mean (Sequence[float]): Medias para normalización.\n",
    "        std (Sequence[float]): Desvíos estándar para normalización.\n",
    "\n",
    "    Returns:\n",
    "        transforms.Compose: Transformación compuesta lista para usar.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: Si torchvision no está disponible en el entorno.\n",
    "    \"\"\"\n",
    "    if transforms is None:\n",
    "        raise RuntimeError(\"torchvision no está disponible en el entorno.\")\n",
    "\n",
    "    return transforms.Compose([\n",
    "        MaxResize(max_size=max_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94dba2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# cargar modelo en el notebook\n",
    "structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "    \"microsoft/table-structure-recognition-v1.1-all\"\n",
    ").to(device)\n",
    "\n",
    "structure_transform = transforms.Compose([\n",
    "    MaxResize(1000),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a24379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 690, 1000])\n"
     ]
    }
   ],
   "source": [
    "pixel_values = structure_transform(cropped_table).unsqueeze(0)\n",
    "pixel_values = pixel_values.to(device)\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82368c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "with torch.no_grad():\n",
    "  outputs = structure_model(pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d07bb3",
   "metadata": {},
   "source": [
    "id2label me tira con las opciones que me puede dar la tabla que son:\n",
    "\n",
    "* table\n",
    "* table header\n",
    "* etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "561fd8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'table column', 'score': 0.9999914169311523, 'bbox': [71.0396499633789, 18.333629608154297, 372.3055419921875, 692.390380859375]}, {'label': 'table row', 'score': 0.9998055100440979, 'bbox': [8.559820175170898, 167.4796600341797, 1030.1776123046875, 271.1231994628906]}, {'label': 'table column', 'score': 0.9999634027481079, 'bbox': [835.1494140625, 19.05427360534668, 938.7198486328125, 692.7470092773438]}, {'label': 'table column', 'score': 0.9999054670333862, 'bbox': [492.745361328125, 18.53667449951172, 746.7467041015625, 692.6864013671875]}, {'label': 'table column', 'score': 0.9998608827590942, 'bbox': [747.0014038085938, 18.84082794189453, 833.9036865234375, 692.5086059570312]}, {'label': 'table row', 'score': 0.9994695782661438, 'bbox': [8.504619598388672, 75.78985595703125, 1029.8843994140625, 113.44821166992188]}, {'label': 'table column', 'score': 0.9999246597290039, 'bbox': [938.3115234375, 19.059001922607422, 1030.29296875, 692.8472290039062]}, {'label': 'table column header', 'score': 0.9994816184043884, 'bbox': [8.45939826965332, 18.7012882232666, 1029.9100341796875, 75.73564910888672]}, {'label': 'table row', 'score': 0.99962317943573, 'bbox': [8.80321979522705, 113.23893737792969, 1030.141845703125, 168.59051513671875]}, {'label': 'table row', 'score': 0.9998028874397278, 'bbox': [8.65903377532959, 587.2471923828125, 1029.69140625, 618.0838623046875]}, {'label': 'table column', 'score': 0.999943733215332, 'bbox': [372.4429626464844, 18.72506332397461, 490.5516357421875, 692.7940063476562]}, {'label': 'table row', 'score': 0.9997281432151794, 'bbox': [8.606746673583984, 526.7470092773438, 1029.68115234375, 556.7249755859375]}, {'label': 'table', 'score': 0.9999914169311523, 'bbox': [8.653702735900879, 18.764863967895508, 1030.21240234375, 692.87548828125]}, {'label': 'table row', 'score': 0.9998445510864258, 'bbox': [8.601570129394531, 469.41790771484375, 1029.9765625, 525.4729614257812]}, {'label': 'table row', 'score': 0.9977518916130066, 'bbox': [8.638391494750977, 266.2005310058594, 1030.3507080078125, 415.7516174316406]}, {'label': 'table row', 'score': 0.9993541836738586, 'bbox': [8.690183639526367, 618.1936645507812, 1029.6708984375, 693.88427734375]}, {'label': 'table column', 'score': 0.9998422861099243, 'bbox': [8.689079284667969, 18.99335289001465, 71.32526397705078, 692.4724731445312]}, {'label': 'table row', 'score': 0.9993441700935364, 'bbox': [8.563974380493164, 415.64642333984375, 1030.174072265625, 468.2033386230469]}, {'label': 'table row', 'score': 0.9998672008514404, 'bbox': [8.474431037902832, 18.769697189331055, 1029.94677734375, 75.63394165039062]}, {'label': 'table row', 'score': 0.9998606443405151, 'bbox': [8.419229507446289, 557.2742919921875, 1029.7833251953125, 587.1445922851562]}]\n"
     ]
    }
   ],
   "source": [
    "# armás el id2label según tu proyecto\n",
    "structure_id2label = structure_model.config.id2label\n",
    "structure_id2label[len(structure_id2label)] = \"no object\"\n",
    "# si en tu caso no hace falta \"no object\", no lo agregás\n",
    "\n",
    "cells = outputs_to_objects(outputs, cropped_table.size, structure_id2label)\n",
    "\n",
    "print(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959a32e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 11\n",
      "Cols: 7\n",
      "Cells (counted): 77\n",
      "Header rows: [0]\n",
      "Row header cols: []\n",
      "Row 0: ['Rank', 'Protein domains', 'Relevant pathway', 'Cellular component', 'Gene count', 'Quality”', 'P-value']\n",
      "Row 1: ['1', 'Phospholipase A2', 'hsa0592', 'Extracellular region (63%)', '20', 'O878', '434E-08']\n",
      "Row 2: ['>', 'THF dehydrogenase; formy] transferase; SHMT;', 'hsa00670', 'Mitochondrion (44%)', '', '0891', '1.79E-07']\n",
      "Row 3: ['3', 'Sialyltransferase; GTF, family 31; GTF, family 11; GH, family 20', 'hsa00603', 'Golgi apparatus (76%)', '17', '0.756', '2.7TE-06']\n",
      "Row 4: ['4', 'Four-helical cytokine, core: IL-4; IL-17, TNF 2; Peroxidases heam-ligand binding site: Toll-ILR MHC class I, a chain, al and a2', 'hsa05310', 'Extracellular space (52%)', '27', '0598', '3.72E-06']\n",
      "Row 5: ['5', 'Immunoglobulin C-Type', 'hsa05310', 'MHC class II protein complex (10046)', '9', '0.793', 'S.98E-04']\n",
      "Row 6: ['6', 'GPCR, rhodopsin-like superfamily', 'NA', 'Integral to plasma membrane (75%)', '12', 'OS5T8', '7 86E-04']\n",
      "Row 7: ['7', 'NA', 'NA', 'Synaptic vesicle (43%)', '8', '0.701', '0.001']\n",
      "Row 8: ['8', 'NA', 'NA', 'NA', '6', '0.645', '0.005']\n",
      "Row 9: ['9', 'NA', 'NA', 'NA', '6', '0625', '0.007']\n",
      "Row 10: ['10', \"3'S'-cyclic nucleotide PDE; adenylyl cyclase class-3/4/ guanylyl cyclase, conserved site\", 'NA', 'NA', '7', 'o7n', '0.007']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 3) Construir grilla con merges de spans\n",
    "pack = build_grid_with_spans(cells)\n",
    "\n",
    "# 4) Completar OCR por celda (sobre la imagen original)\n",
    "pack = fill_grid_with_ocr(\n",
    "    grid_pack=pack,\n",
    "    image_path=\"tabla.jpg\",           # ruta a la misma imagen usada para el modelo\n",
    "    tess_cfg=\"--oem 3 --psm 6\",       # ajustá PSM si hace falta\n",
    "    skip_headers=False,               # poné True si querés saltear headers\n",
    ")\n",
    "\n",
    "# 4) Acceder a resultados\n",
    "print(\"Rows:\", pack[\"n_rows\"])\n",
    "print(\"Cols:\", pack[\"n_cols\"])\n",
    "print(\"Cells (counted):\", pack[\"cells_counted\"])\n",
    "print(\"Header rows:\", pack[\"header_rows\"])\n",
    "print(\"Row header cols:\", pack[\"row_header_cols\"])\n",
    "\n",
    "# 5) Ejemplo: recorrer la grilla\n",
    "grid = pack[\"grid\"]\n",
    "for r in range(pack[\"n_rows\"]):\n",
    "    row_texts = [cell[\"text\"] for cell in grid[r] if not cell[\"covered\"]]\n",
    "    print(f\"Row {r}: {row_texts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d888c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: ['Rank', 'Protein domains', 'Relevant pathway', 'Cellular component', 'Gene count', 'Quality”', 'P-value']\n",
      "Row 1: ['1', 'Phospholipase A2', 'hsa0592', 'Extracellular region (63%)', '20', 'O878', '34E-08 4']\n",
      "Row 2: ['2', 'THF dehydrogenase; formy] transferase; SHMT;', 'hsal0670—-', 'Mitochondrion (44%)', '18', '0891', '1.79B-07']\n",
      "Row 3: ['3', 'Sialyltransferase; GTF, family 31; GTF, family 11; GH, family 20', 'hsa00603', 'Golgi (76%) apparatus', '17', '0.756', '2.77TE-06']\n",
      "Row 4: ['4', 'Four-helical cytokine, core: IL-4: IL-17, TNF 2; Peroxidases heam-ligand binding site: Toll-ILR a MHC class I, chain, and «2 acl', 'hsa05310', 'Extracellular (52%) space', '27', '0598', '3.72E-06']\n",
      "Row 5: ['3', 'Immunoglobulin C-Type', 'hsa05310', 'MHC class II protein complex (100%)', '9', '0.793', 'S.98E-04']\n",
      "Row 6: ['6', 'GPCR, rhodopsin-like superfamily', 'nan', 'Integral plasma to membrane (75%)', '12', 'O578', '7R6E-O4']\n",
      "Row 7: ['7', 'nan', 'nan', 'Synaptic vesicle (43%)', '8', '0.701', '0.001']\n",
      "Row 8: ['8', 'nan', 'nan', 'nan', '6', '0645', '0.005']\n",
      "Row 9: ['9', 'nan', 'nan', 'nan', '6', '0.625', '0.007']\n",
      "Row 10: ['10', \"3'S'-cyclic nucleotide PDE; adenylyl cyclase class-3/4/ cyclase, conserved guanylyl site\", 'nan', 'nan', '7', 'O71', '0.007']\n"
     ]
    }
   ],
   "source": [
    "# 3) Armar grilla (con spans/headers)\n",
    "pack = build_grid_with_spans(cells, iou_th=0.6, overlap_th=0.5)\n",
    "\n",
    "# 4) OCR global → asignación por centro\n",
    "pack = fill_grid_from_global_ocr_centered(\n",
    "    grid_pack=pack,\n",
    "    image_path=\"tabla.jpg\",\n",
    "    tess_cfg=\"--oem 3 --psm 6\",\n",
    "    min_conf=0,          # subí si hay ruido (por ej., 40-60)\n",
    "    joiner=\" \",\n",
    "    skip_headers=False,\n",
    ")\n",
    "\n",
    "# 5) Visualizar en Colab/Jupyter\n",
    "# 5) Ejemplo: recorrer la grilla\n",
    "grid = pack[\"grid\"]\n",
    "for r in range(pack[\"n_rows\"]):\n",
    "    row_texts = [cell[\"text\"] for cell in grid[r] if not cell[\"covered\"]]\n",
    "    print(f\"Row {r}: {row_texts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39e60c",
   "metadata": {},
   "source": [
    "## Visualización de imagenes por tipo (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TATR_OCR import draw_tatr_overlays_multi\n",
    "\n",
    "# detections es la lista de dicts que obtuviste con outputs_to_objects(...)\n",
    "detections = cells  \n",
    "\n",
    "# ruta de la imagen original que procesaste con el modelo\n",
    "image_path = \"table.jpg\"\n",
    "\n",
    "# carpeta de salida (ej: \"../temp\" si está fuera de notebooks/)\n",
    "out_dir = \"../temp\"\n",
    "\n",
    "# generar las imágenes con overlays\n",
    "paths = draw_tatr_overlays_multi(\n",
    "    image_path=image_path,\n",
    "    detections=detections,\n",
    "    out_dir=out_dir,\n",
    "    alpha=0.3,       # transparencia (0=sin relleno, 1=totalmente opaco)\n",
    "    thickness=2,     # grosor de los bordes\n",
    "    put_labels=True  # si mostrar etiquetas de clase y score\n",
    ")\n",
    "\n",
    "print(\"Imágenes generadas:\")\n",
    "for k, v in paths.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea39762",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Se van a sacar las siguientes estadísticas para el estudio de 100 imágenes random del dataset de pubtabnet:\n",
    "\n",
    "* Tamaño de la imagen\n",
    "* Cantidad de filas reales\n",
    "* Cantidad de filas predichas\n",
    "* Cantidad de columnas reales\n",
    "* Cantidad de columnas predichas\n",
    "* Cantidad de celdas reales\n",
    "* Cantidad de celdas predichas\n",
    "* Row Precision\n",
    "* Column Precision\n",
    "* Cell Precision\n",
    "* WRC Global\n",
    "* WCC Global\n",
    "* CER Promedio\n",
    "* CER Global\n",
    "\n",
    "$\\text{precision} = 1 - \\dfrac{|\\text{pred} - \\text{gt}|}{\\text{gt}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2a2f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a27dbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para tratar con el ground truth en formato json\n",
    "from typing import Dict, Literal, Any, List\n",
    "from jiwer import cer\n",
    "\n",
    "def count_structure_from_pubtabnet(gt: Dict) -> Dict[str, int]:\n",
    "    \"\"\"Cuenta rows, cols y cells usando html.structure.tokens de PubTabNet-like.\n",
    "\n",
    "    Reglas:\n",
    "    - rows: cantidad de <tr>\n",
    "    - cols: máximo nº de celdas por fila (cuenta <td> y <th> entre <tr> ... </tr>)\n",
    "    - cells: total de celdas (<td> + <th>) en toda la tabla\n",
    "\n",
    "    Args:\n",
    "        gt: dict con clave 'html' -> {'structure': {'tokens': [...]}}.\n",
    "\n",
    "    Returns:\n",
    "        {'rows': int, 'cols': int, 'cells': int}\n",
    "    \"\"\"\n",
    "    tokens: List[str] = gt[\"html\"][\"structure\"][\"tokens\"]\n",
    "    rows = 0\n",
    "    max_cols = 0\n",
    "    total_cells = 0\n",
    "\n",
    "    in_row = False\n",
    "    cells_in_current_row = 0\n",
    "\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        tok = tokens[i]\n",
    "\n",
    "        if tok == \"<tr>\":\n",
    "            # cerrar fila previa si quedó abierta (por robustez)\n",
    "            if in_row:\n",
    "                rows += 1\n",
    "                max_cols = max(max_cols, cells_in_current_row)\n",
    "                cells_in_current_row = 0\n",
    "            in_row = True\n",
    "\n",
    "        elif tok in (\"</tr>\",):\n",
    "            if in_row:\n",
    "                rows += 1\n",
    "                max_cols = max(max_cols, cells_in_current_row)\n",
    "                cells_in_current_row = 0\n",
    "                in_row = False\n",
    "\n",
    "        elif tok in (\"<td>\", \"<th>\"):\n",
    "            total_cells += 1\n",
    "            if in_row:\n",
    "                cells_in_current_row += 1\n",
    "\n",
    "        # ignoramos otros tokens (<thead>, </thead>, <tbody>, </tbody>, </td>, </th>, etc.)\n",
    "        i += 1\n",
    "\n",
    "    # si terminó el stream con una fila abierta (sin </tr>)\n",
    "    if in_row:\n",
    "        rows += 1\n",
    "        max_cols = max(max_cols, cells_in_current_row)\n",
    "\n",
    "    return {\"rows\": rows, \"cols\": max_cols, \"cells\": total_cells}\n",
    "\n",
    "def structure_precision_counts(\n",
    "    pred_stats: Dict[str, int],\n",
    "    gt_stats: Dict[str, int],\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Compara conteos de estructura (rows/cols/cells) entre pred y GT y calcula precisión.\n",
    "\n",
    "    La métrica se define como:\n",
    "        precision = 1 - |pred - gt| / gt\n",
    "\n",
    "    Args:\n",
    "        pred_stats: {'rows': int, 'cols': int, 'cells': int} predichos.\n",
    "        gt_stats:   {'rows': int, 'cols': int, 'cells': int} ground truth.\n",
    "\n",
    "    Returns:\n",
    "        Dict con claves 'rows', 'cols', 'cells'. Cada una contiene:\n",
    "            - gt: int\n",
    "            - pred: int\n",
    "            - delta: int (pred - gt)\n",
    "            - precision: float entre 0 y 1\n",
    "    \"\"\"\n",
    "    out: Dict[str, Dict[str, float]] = {}\n",
    "    for key in (\"rows\", \"cols\", \"cells\"):\n",
    "        gt_val = int(gt_stats.get(key, 0))\n",
    "        pred_val = int(pred_stats.get(key, 0))\n",
    "        delta = pred_val - gt_val\n",
    "\n",
    "        if gt_val == 0:\n",
    "            # si el GT no tiene valor, definimos precision = 1 si pred==0, si no 0\n",
    "            precision = 1.0 if pred_val == 0 else 0.0\n",
    "        else:\n",
    "            precision = 1 - abs(delta) / gt_val\n",
    "            precision = max(0.0, min(1.0, precision))  # clamp a [0,1]\n",
    "\n",
    "        out[key] = {\n",
    "            \"gt\": gt_val,\n",
    "            \"pred\": pred_val,\n",
    "            \"delta\": delta,\n",
    "            \"precision\": precision,\n",
    "        }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d9d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_words_from_pubtabnet(gt: Dict[str, Any]) -> int:\n",
    "    \"\"\"Reconstruye texto de celdas y cuenta palabras en todo el GT.\n",
    "\n",
    "    Args:\n",
    "        gt: dict con clave 'html' -> {'cells': [{'tokens': [...]}]}.\n",
    "\n",
    "    Returns:\n",
    "        Número total de palabras.\n",
    "    \"\"\"\n",
    "    total_words = 0\n",
    "    for cell in gt[\"html\"][\"cells\"]:\n",
    "        tokens = cell.get(\"tokens\", [])\n",
    "        # unir tokens en un string completo\n",
    "        text = \"\".join(\n",
    "            t for t in tokens \n",
    "            if not (t.startswith(\"<\") and t.endswith(\">\"))  # descartar tags\n",
    "        )\n",
    "        # dividir por espacios\n",
    "        words = [w for w in text.split(\" \") if w.strip()]\n",
    "        total_words += len(words)\n",
    "    return total_words\n",
    "\n",
    "def reconstruct_gt_cells(gt: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Reconstruye el texto de cada celda en GT PubTabNet.\"\"\"\n",
    "    cells = []\n",
    "    for cell in gt[\"html\"][\"cells\"]:\n",
    "        tokens = cell.get(\"tokens\", [])\n",
    "        text = \"\".join(t for t in tokens if not (t.startswith(\"<\") and t.endswith(\">\")))\n",
    "        text = \" \".join(text.split())  # normalizar espacios\n",
    "        cells.append(text)\n",
    "    return cells\n",
    "\n",
    "def flatten_pred_rows(pred_rows: List[List[str]]) -> List[str]:\n",
    "    \"\"\"Convierte predicción en lista plana de celdas.\"\"\"\n",
    "    return [c.strip() for row in pred_rows for c in row]\n",
    "\n",
    "def wrc_single(n_gt: int, n_pred: int) -> float:\n",
    "    \"\"\"Word Rate Count para un par de conteos.\"\"\"\n",
    "    if n_gt == 0:\n",
    "        return 1.0 if n_pred == 0 else 0.0\n",
    "    wrc = 1 - abs(n_pred - n_gt) / n_gt\n",
    "    return max(0.0, min(1.0, wrc))\n",
    "\n",
    "def wrc_global(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"WRC considerando todas las palabras de la tabla.\"\"\"\n",
    "    n_gt = sum(len(c.split()) for c in gt_cells)\n",
    "    n_pred = sum(len(c.split()) for c in pred_cells)\n",
    "    return wrc_single(n_gt, n_pred)\n",
    "\n",
    "def wrc_cellwise(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"WRC promedio celda a celda.\"\"\"\n",
    "    n = len(gt_cells)\n",
    "    if n == 0:\n",
    "        return 1.0\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        gt_text = gt_cells[i] if i < len(gt_cells) else \"\"\n",
    "        pred_text = pred_cells[i] if i < len(pred_cells) else \"\"\n",
    "        scores.append(wrc_single(len(gt_text.split()), len(pred_text.split())))\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "def cer_pair(gt: str, pred: str) -> float:\n",
    "    \"\"\"CER entre dos textos normalizados.\"\"\"\n",
    "    gt_norm = \" \".join(gt.split())\n",
    "    pred_norm = \" \".join(pred.split())\n",
    "    if not gt_norm:\n",
    "        return 0.0 if not pred_norm else 1.0\n",
    "    return float(cer(gt_norm, pred_norm))\n",
    "\n",
    "def cer_global(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"CER considerando toda la tabla concatenada.\"\"\"\n",
    "    gt_text = \" \".join(\" \".join(c.split()) for c in gt_cells).strip()\n",
    "    pred_text = \" \".join(\" \".join(c.split()) for c in pred_cells).strip()\n",
    "    return cer_pair(gt_text, pred_text)\n",
    "\n",
    "def cer_cellwise(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"CER promedio celda a celda.\"\"\"\n",
    "    n = len(gt_cells)\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        gt_text = gt_cells[i] if i < len(gt_cells) else \"\"\n",
    "        pred_text = pred_cells[i] if i < len(pred_cells) else \"\"\n",
    "        scores.append(cer_pair(gt_text, pred_text))\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96b151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No GT para PMC1180437_003_01.png, se saltea\n",
      "⚠️ No GT para PMC1215488_007_00.png, se saltea\n",
      "⚠️ No GT para PMC1796903_013_00.png, se saltea\n",
      "⚠️ No GT para PMC2174470_003_00.png, se saltea\n",
      "⚠️ No GT para PMC2654114_006_00.png, se saltea\n",
      "⚠️ No GT para PMC2679760_005_00.png, se saltea\n",
      "⚠️ No GT para PMC2688351_005_00.png, se saltea\n",
      "⚠️ No GT para PMC2741432_008_00.png, se saltea\n",
      "⚠️ No GT para PMC2781010_008_00.png, se saltea\n",
      "⚠️ No GT para PMC2837001_002_01.png, se saltea\n",
      "⚠️ No GT para PMC3042936_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3103444_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3213066_006_00.png, se saltea\n",
      "⚠️ No GT para PMC3284427_006_01.png, se saltea\n",
      "⚠️ No GT para PMC3296643_002_00.png, se saltea\n",
      "⚠️ No GT para PMC3349608_002_00.png, se saltea\n",
      "⚠️ No GT para PMC3399222_010_00.png, se saltea\n",
      "⚠️ No GT para PMC3414058_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3426469_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3442972_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3448500_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3465184_007_01.png, se saltea\n",
      "⚠️ No GT para PMC3469388_004_01.png, se saltea\n",
      "⚠️ No GT para PMC3488582_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3492817_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3543344_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3568058_002_00.png, se saltea\n",
      "⚠️ No GT para PMC3571792_009_00.png, se saltea\n",
      "⚠️ No GT para PMC3590442_001_01.png, se saltea\n",
      "⚠️ No GT para PMC3600185_004_02.png, se saltea\n",
      "⚠️ No GT para PMC3751346_006_00.png, se saltea\n",
      "⚠️ No GT para PMC3791439_003_01.png, se saltea\n",
      "⚠️ No GT para PMC3797049_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3851160_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3857257_005_00.png, se saltea\n",
      "⚠️ No GT para PMC3879098_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3973997_006_00.png, se saltea\n",
      "⚠️ No GT para PMC4048619_005_00.png, se saltea\n",
      "⚠️ No GT para PMC4106230_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4107379_005_00.png, se saltea\n",
      "⚠️ No GT para PMC4152582_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4216381_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4234831_004_00.png, se saltea\n",
      "⚠️ No GT para PMC4300612_001_00.png, se saltea\n",
      "⚠️ No GT para PMC4403562_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4417574_004_00.png, se saltea\n",
      "⚠️ No GT para PMC4443755_003_00.png, se saltea\n",
      "⚠️ No GT para PMC4573746_004_00.png, se saltea\n",
      "⚠️ No GT para PMC4587579_009_00.png, se saltea\n",
      "⚠️ No GT para PMC4591530_007_00.png, se saltea\n",
      "⚠️ No GT para PMC4609470_003_01.png, se saltea\n",
      "⚠️ No GT para PMC4689805_007_00.png, se saltea\n",
      "⚠️ No GT para PMC4714460_006_00.png, se saltea\n",
      "⚠️ No GT para PMC4730439_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4732478_006_00.png, se saltea\n",
      "⚠️ No GT para PMC4736197_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4842305_012_01.png, se saltea\n",
      "⚠️ No GT para PMC4871302_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4873504_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4880972_007_00.png, se saltea\n",
      "⚠️ No GT para PMC4908466_006_01.png, se saltea\n",
      "⚠️ No GT para PMC4980790_011_00.png, se saltea\n",
      "⚠️ No GT para PMC5027634_009_00.png, se saltea\n",
      "⚠️ No GT para PMC5028949_005_00.png, se saltea\n",
      "⚠️ No GT para PMC5050670_005_01.png, se saltea\n",
      "⚠️ No GT para PMC5111420_005_00.png, se saltea\n",
      "⚠️ No GT para PMC5124310_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5154142_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5155125_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5159971_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5297745_009_00.png, se saltea\n",
      "⚠️ No GT para PMC5352876_001_00.png, se saltea\n",
      "⚠️ No GT para PMC5364675_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5406936_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5435261_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5448947_003_00.png, se saltea\n",
      "⚠️ No GT para PMC5472948_004_01.png, se saltea\n",
      "⚠️ No GT para PMC5510103_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5517789_003_00.png, se saltea\n",
      "⚠️ No GT para PMC5597084_015_01.png, se saltea\n",
      "⚠️ No GT para PMC5606674_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5620310_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5673733_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5676673_019_00.png, se saltea\n",
      "⚠️ No GT para PMC5686943_001_00.png, se saltea\n",
      "⚠️ No GT para PMC5706893_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5715995_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5751014_009_00.png, se saltea\n",
      "⚠️ No GT para PMC5877327_022_01.png, se saltea\n",
      "⚠️ No GT para PMC5923382_006_00.png, se saltea\n",
      "⚠️ No GT para PMC5932779_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5952850_005_00.png, se saltea\n",
      "⚠️ No GT para PMC5978059_016_00.png, se saltea\n",
      "⚠️ No GT para PMC5980498_003_00.png, se saltea\n",
      "⚠️ No GT para PMC5982508_005_00.png, se saltea\n",
      "⚠️ No GT para PMC6063011_004_00.png, se saltea\n",
      "⚠️ No GT para PMC6071173_002_00.png, se saltea\n",
      "                filename  img_w  img_h  gt_rows  pred_rows  gt_cols  \\\n",
      "0  PMC1232864_004_01.png    503    157       13         13        4   \n",
      "1  PMC1310919_004_00.png    344    103       10         10        6   \n",
      "2  PMC1534032_004_01.png    503    373       34         38        2   \n",
      "3  PMC1559691_002_00.png    503    557       43         50        6   \n",
      "4  PMC1570152_006_00.png    246    137       11         11        7   \n",
      "\n",
      "   pred_cols  gt_cells  pred_cells  row_precision  col_precision  \\\n",
      "0          4        44          51       1.000000            1.0   \n",
      "1          6        60          60       1.000000            1.0   \n",
      "2          2        68          76       0.882353            1.0   \n",
      "3          6       258         300       0.837209            1.0   \n",
      "4          7        77          77       1.000000            1.0   \n",
      "\n",
      "   cell_precision  wrc_global   wrc_avg  cer_global   cer_avg  \n",
      "0        0.840909    0.170732  0.176087    0.932292  1.012587  \n",
      "1        1.000000    0.065789  0.062500    0.965035  0.994815  \n",
      "2        0.882353    0.408451  0.044118    0.883234  2.230949  \n",
      "3        0.837209    0.308793  0.250111    0.880734  0.932266  \n",
      "4        1.000000    0.093023  0.071429    0.961864  1.010823  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# --- Asumimos que ya tenés estas funciones definidas ---\n",
    "# count_structure_from_pubtabnet\n",
    "# structure_precision_counts\n",
    "# reconstruct_gt_cells\n",
    "# flatten_pred_rows\n",
    "# wrc_global, wrc_cellwise\n",
    "# cer_global, cer_cellwise\n",
    "\n",
    "# --- Paths ---\n",
    "image_dir = Path(\"..\\\\data\\\\regions\\\\table\")               # carpeta con imágenes\n",
    "gt_path = Path(\"..\\\\data\\\\annotations\\\\ocr_table_labels.json\")      # ground truth PubTabNet-style\n",
    "\n",
    "# --- Cargar GT en un diccionario: filename -> objeto completo ---\n",
    "gt_map = {}\n",
    "with gt_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        filename = obj.get(\"filename\")\n",
    "        if filename:\n",
    "            gt_map[filename] = obj\n",
    "\n",
    "# --- Iterar imágenes ---\n",
    "rows_out = []\n",
    "exts = {\".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "for img_path in sorted(image_dir.iterdir()):\n",
    "    if img_path.suffix.lower() not in exts:\n",
    "        continue\n",
    "\n",
    "    filename = img_path.name\n",
    "    gt = gt_map.get(filename)\n",
    "    if gt is None:\n",
    "        print(f\"⚠️ No GT para {filename}, se saltea\")\n",
    "        continue\n",
    "\n",
    "    # --- Tamaño de la imagen ---\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    # --- Conteos reales (GT) ---\n",
    "    gt_counts = count_structure_from_pubtabnet(gt)\n",
    "    gt_cells = reconstruct_gt_cells(gt)\n",
    "\n",
    "    # --- Conteos predichos y textos ---\n",
    "    # acá usás tu pipeline para obtener pack[\"grid\"]\n",
    "    # 1) Aplico el modelo de TATR a la imagen\n",
    "    structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "        \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "    ).to(device)\n",
    "\n",
    "    structure_transform = transforms.Compose([\n",
    "        MaxResize(1000),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    pixel_values = structure_transform(img).unsqueeze(0)\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = structure_model(pixel_values)\n",
    "    \n",
    "    # 2) Paso los datos crudos del tatr a lo legible\n",
    "    structure_id2label = structure_model.config.id2label\n",
    "    structure_id2label[len(structure_id2label)] = \"no object\"\n",
    "    cells = outputs_to_objects(outputs, img.size, structure_id2label)\n",
    "    \n",
    "    # 3) Construir grilla con merges de spans\n",
    "    pack = build_grid_with_spans(cells)\n",
    "\n",
    "    # 4) Completar OCR por celda (sobre la imagen original)\n",
    "    pack = fill_grid_with_ocr(\n",
    "        grid_pack=pack,\n",
    "        image_path=\"tabla.jpg\",           # ruta a la misma imagen usada para el modelo\n",
    "        tess_cfg=\"--oem 3 --psm 6\",       # ajustá PSM si hace falta\n",
    "        skip_headers=False,               # poné True si querés saltear headers\n",
    "    )\n",
    "    grid = pack[\"grid\"]\n",
    "\n",
    "    pred_rows = []\n",
    "    for r in range(pack[\"n_rows\"]):\n",
    "        row_texts = [cell[\"text\"] for cell in grid[r] if not cell[\"covered\"]]\n",
    "        pred_rows.append(row_texts)\n",
    "\n",
    "    pred_cells = flatten_pred_rows(pred_rows)\n",
    "    pred_counts = {\n",
    "        \"rows\": pack[\"n_rows\"],\n",
    "        \"cols\": pack[\"n_cols\"],\n",
    "        \"cells\": pack[\"cells_counted\"],  # asumimos que tu pack trae esto\n",
    "    }\n",
    "\n",
    "    # --- Precisiones estructurales ---\n",
    "    comp = structure_precision_counts(pred_counts, gt_counts)\n",
    "\n",
    "    # --- Métricas WRC y CER ---\n",
    "    wrc_g = wrc_global(gt_cells, pred_cells)\n",
    "    wrc_c = wrc_cellwise(gt_cells, pred_cells)\n",
    "    cer_g = cer_global(gt_cells, pred_cells)\n",
    "    cer_c = cer_cellwise(gt_cells, pred_cells)\n",
    "\n",
    "    # --- Registrar resultados ---\n",
    "    rows_out.append({\n",
    "        \"filename\": filename,\n",
    "        \"img_w\": img_w,\n",
    "        \"img_h\": img_h,\n",
    "        \"gt_rows\": gt_counts[\"rows\"],\n",
    "        \"pred_rows\": pred_counts[\"rows\"],\n",
    "        \"gt_cols\": gt_counts[\"cols\"],\n",
    "        \"pred_cols\": pred_counts[\"cols\"],\n",
    "        \"gt_cells\": gt_counts[\"cells\"],\n",
    "        \"pred_cells\": pred_counts[\"cells\"],\n",
    "        \"row_precision\": comp[\"rows\"][\"precision\"],\n",
    "        \"col_precision\": comp[\"cols\"][\"precision\"],\n",
    "        \"cell_precision\": comp[\"cells\"][\"precision\"],\n",
    "        \"wrc_global\": wrc_g,\n",
    "        \"wrc_avg\": wrc_c,\n",
    "        \"cer_global\": cer_g,\n",
    "        \"cer_avg\": cer_c,\n",
    "    })\n",
    "\n",
    "# --- DataFrame final ---\n",
    "df_results_1 = pd.DataFrame(rows_out)\n",
    "df_results_1.to_csv(\"metrics_results_1.csv\", index=False)\n",
    "print(df_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "378b728f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>img_w</th>\n",
       "      <th>img_h</th>\n",
       "      <th>gt_rows</th>\n",
       "      <th>pred_rows</th>\n",
       "      <th>gt_cols</th>\n",
       "      <th>pred_cols</th>\n",
       "      <th>gt_cells</th>\n",
       "      <th>pred_cells</th>\n",
       "      <th>row_precision</th>\n",
       "      <th>col_precision</th>\n",
       "      <th>cell_precision</th>\n",
       "      <th>wrc_global</th>\n",
       "      <th>wrc_avg</th>\n",
       "      <th>cer_global</th>\n",
       "      <th>cer_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC1232864_004_01.png</td>\n",
       "      <td>503</td>\n",
       "      <td>157</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.176087</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>1.012587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC1310919_004_00.png</td>\n",
       "      <td>344</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.994815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC1534032_004_01.png</td>\n",
       "      <td>503</td>\n",
       "      <td>373</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.883234</td>\n",
       "      <td>2.230949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC1559691_002_00.png</td>\n",
       "      <td>503</td>\n",
       "      <td>557</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>258</td>\n",
       "      <td>300</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.308793</td>\n",
       "      <td>0.250111</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>0.932266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC1570152_006_00.png</td>\n",
       "      <td>246</td>\n",
       "      <td>137</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.961864</td>\n",
       "      <td>1.010823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PMC5876629_005_00.png</td>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>1.391604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PMC5928814_004_01.png</td>\n",
       "      <td>243</td>\n",
       "      <td>212</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.189542</td>\n",
       "      <td>0.100649</td>\n",
       "      <td>0.908405</td>\n",
       "      <td>1.043463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PMC5977059_004_00.png</td>\n",
       "      <td>502</td>\n",
       "      <td>194</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.165957</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.933740</td>\n",
       "      <td>0.897559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PMC6025574_003_00.png</td>\n",
       "      <td>404</td>\n",
       "      <td>337</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994536</td>\n",
       "      <td>0.482270</td>\n",
       "      <td>0.300901</td>\n",
       "      <td>0.903651</td>\n",
       "      <td>0.795572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PMC6071402_003_03.png</td>\n",
       "      <td>238</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.962656</td>\n",
       "      <td>1.025794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename  img_w  img_h  gt_rows  pred_rows  gt_cols  \\\n",
       "0   PMC1232864_004_01.png    503    157       13         13        4   \n",
       "1   PMC1310919_004_00.png    344    103       10         10        6   \n",
       "2   PMC1534032_004_01.png    503    373       34         38        2   \n",
       "3   PMC1559691_002_00.png    503    557       43         50        6   \n",
       "4   PMC1570152_006_00.png    246    137       11         11        7   \n",
       "..                    ...    ...    ...      ...        ...      ...   \n",
       "95  PMC5876629_005_00.png    317    110        7          7        3   \n",
       "96  PMC5928814_004_01.png    243    212       19         18        3   \n",
       "97  PMC5977059_004_00.png    502    194       17         17        9   \n",
       "98  PMC6025574_003_00.png    404    337       27         27        7   \n",
       "99  PMC6071402_003_03.png    238    109        7          7        6   \n",
       "\n",
       "    pred_cols  gt_cells  pred_cells  row_precision  col_precision  \\\n",
       "0           4        44          51       1.000000            1.0   \n",
       "1           6        60          60       1.000000            1.0   \n",
       "2           2        68          76       0.882353            1.0   \n",
       "3           6       258         300       0.837209            1.0   \n",
       "4           7        77          77       1.000000            1.0   \n",
       "..        ...       ...         ...            ...            ...   \n",
       "95          3        17          19       1.000000            1.0   \n",
       "96          3        54          54       0.947368            1.0   \n",
       "97          9       141         153       1.000000            1.0   \n",
       "98          7       183         184       1.000000            1.0   \n",
       "99          6        42          42       1.000000            1.0   \n",
       "\n",
       "    cell_precision  wrc_global   wrc_avg  cer_global   cer_avg  \n",
       "0         0.840909    0.170732  0.176087    0.932292  1.012587  \n",
       "1         1.000000    0.065789  0.062500    0.965035  0.994815  \n",
       "2         0.882353    0.408451  0.044118    0.883234  2.230949  \n",
       "3         0.837209    0.308793  0.250111    0.880734  0.932266  \n",
       "4         1.000000    0.093023  0.071429    0.961864  1.010823  \n",
       "..             ...         ...       ...         ...       ...  \n",
       "95        0.882353    0.291667  0.131579    0.864662  1.391604  \n",
       "96        1.000000    0.189542  0.100649    0.908405  1.043463  \n",
       "97        0.914894    0.165957  0.244681    0.933740  0.897559  \n",
       "98        0.994536    0.482270  0.300901    0.903651  0.795572  \n",
       "99        1.000000    0.115385  0.083333    0.962656  1.025794  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ededd56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_w             390.360000\n",
      "img_h             221.510000\n",
      "gt_rows            15.480000\n",
      "pred_rows          15.840000\n",
      "gt_cols             4.830000\n",
      "pred_cols           4.890000\n",
      "gt_cells           65.870000\n",
      "pred_cells         72.870000\n",
      "row_precision       0.968008\n",
      "col_precision       0.980726\n",
      "cell_precision      0.906645\n",
      "wrc_global          0.286189\n",
      "wrc_avg             0.188910\n",
      "cer_global          0.898016\n",
      "cer_avg             1.105488\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# mean de todas las columnas numéricas\n",
    "df_mean = df_results.mean(numeric_only=True)\n",
    "\n",
    "print(df_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1d800",
   "metadata": {},
   "source": [
    "Mismo ejercicio pero con un scale a la tabla antes de aplicar OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0218ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No GT para PMC1180437_003_01.png, se saltea\n",
      "⚠️ No GT para PMC1215488_007_00.png, se saltea\n",
      "⚠️ No GT para PMC1796903_013_00.png, se saltea\n",
      "⚠️ No GT para PMC2174470_003_00.png, se saltea\n",
      "⚠️ No GT para PMC2654114_006_00.png, se saltea\n",
      "⚠️ No GT para PMC2679760_005_00.png, se saltea\n",
      "⚠️ No GT para PMC2688351_005_00.png, se saltea\n",
      "⚠️ No GT para PMC2741432_008_00.png, se saltea\n",
      "⚠️ No GT para PMC2781010_008_00.png, se saltea\n",
      "⚠️ No GT para PMC2837001_002_01.png, se saltea\n",
      "⚠️ No GT para PMC3042936_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3103444_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3213066_006_00.png, se saltea\n",
      "⚠️ No GT para PMC3284427_006_01.png, se saltea\n",
      "⚠️ No GT para PMC3296643_002_00.png, se saltea\n",
      "⚠️ No GT para PMC3349608_002_00.png, se saltea\n",
      "⚠️ No GT para PMC3399222_010_00.png, se saltea\n",
      "⚠️ No GT para PMC3414058_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3426469_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3442972_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3448500_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3465184_007_01.png, se saltea\n",
      "⚠️ No GT para PMC3469388_004_01.png, se saltea\n",
      "⚠️ No GT para PMC3488582_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3492817_003_00.png, se saltea\n",
      "⚠️ No GT para PMC3543344_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3568058_002_00.png, se saltea\n",
      "⚠️ No GT para PMC3571792_009_00.png, se saltea\n",
      "⚠️ No GT para PMC3590442_001_01.png, se saltea\n",
      "⚠️ No GT para PMC3600185_004_02.png, se saltea\n",
      "⚠️ No GT para PMC3751346_006_00.png, se saltea\n",
      "⚠️ No GT para PMC3791439_003_01.png, se saltea\n",
      "⚠️ No GT para PMC3797049_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3851160_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3857257_005_00.png, se saltea\n",
      "⚠️ No GT para PMC3879098_004_00.png, se saltea\n",
      "⚠️ No GT para PMC3973997_006_00.png, se saltea\n",
      "⚠️ No GT para PMC4048619_005_00.png, se saltea\n",
      "⚠️ No GT para PMC4106230_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4107379_005_00.png, se saltea\n",
      "⚠️ No GT para PMC4152582_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4216381_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4234831_004_00.png, se saltea\n",
      "⚠️ No GT para PMC4300612_001_00.png, se saltea\n",
      "⚠️ No GT para PMC4403562_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4417574_004_00.png, se saltea\n",
      "⚠️ No GT para PMC4443755_003_00.png, se saltea\n",
      "⚠️ No GT para PMC4573746_004_00.png, se saltea\n",
      "⚠️ No GT para PMC4587579_009_00.png, se saltea\n",
      "⚠️ No GT para PMC4591530_007_00.png, se saltea\n",
      "⚠️ No GT para PMC4609470_003_01.png, se saltea\n",
      "⚠️ No GT para PMC4689805_007_00.png, se saltea\n",
      "⚠️ No GT para PMC4714460_006_00.png, se saltea\n",
      "⚠️ No GT para PMC4730439_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4732478_006_00.png, se saltea\n",
      "⚠️ No GT para PMC4736197_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4842305_012_01.png, se saltea\n",
      "⚠️ No GT para PMC4871302_002_00.png, se saltea\n",
      "⚠️ No GT para PMC4873504_004_01.png, se saltea\n",
      "⚠️ No GT para PMC4880972_007_00.png, se saltea\n",
      "⚠️ No GT para PMC4908466_006_01.png, se saltea\n",
      "⚠️ No GT para PMC4980790_011_00.png, se saltea\n",
      "⚠️ No GT para PMC5027634_009_00.png, se saltea\n",
      "⚠️ No GT para PMC5028949_005_00.png, se saltea\n",
      "⚠️ No GT para PMC5050670_005_01.png, se saltea\n",
      "⚠️ No GT para PMC5111420_005_00.png, se saltea\n",
      "⚠️ No GT para PMC5124310_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5154142_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5155125_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5159971_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5297745_009_00.png, se saltea\n",
      "⚠️ No GT para PMC5352876_001_00.png, se saltea\n",
      "⚠️ No GT para PMC5364675_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5406936_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5435261_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5448947_003_00.png, se saltea\n",
      "⚠️ No GT para PMC5472948_004_01.png, se saltea\n",
      "⚠️ No GT para PMC5510103_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5517789_003_00.png, se saltea\n",
      "⚠️ No GT para PMC5597084_015_01.png, se saltea\n",
      "⚠️ No GT para PMC5606674_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5620310_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5673733_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5676673_019_00.png, se saltea\n",
      "⚠️ No GT para PMC5686943_001_00.png, se saltea\n",
      "⚠️ No GT para PMC5706893_002_00.png, se saltea\n",
      "⚠️ No GT para PMC5715995_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5751014_009_00.png, se saltea\n",
      "⚠️ No GT para PMC5877327_022_01.png, se saltea\n",
      "⚠️ No GT para PMC5923382_006_00.png, se saltea\n",
      "⚠️ No GT para PMC5932779_004_00.png, se saltea\n",
      "⚠️ No GT para PMC5952850_005_00.png, se saltea\n",
      "⚠️ No GT para PMC5978059_016_00.png, se saltea\n",
      "⚠️ No GT para PMC5980498_003_00.png, se saltea\n",
      "⚠️ No GT para PMC5982508_005_00.png, se saltea\n",
      "⚠️ No GT para PMC6063011_004_00.png, se saltea\n",
      "⚠️ No GT para PMC6071173_002_00.png, se saltea\n",
      "                filename  img_w  img_h  gt_rows  pred_rows  gt_cols  \\\n",
      "0  PMC1232864_004_01.png   1006    314       13         13        4   \n",
      "1  PMC1310919_004_00.png    688    206       10         10        6   \n",
      "2  PMC1534032_004_01.png   1006    746       34         38        2   \n",
      "3  PMC1559691_002_00.png   1006   1114       43         52        6   \n",
      "4  PMC1570152_006_00.png    492    274       11         11        7   \n",
      "\n",
      "   pred_cols  gt_cells  pred_cells  row_precision  col_precision  \\\n",
      "0          4        44          50       1.000000            1.0   \n",
      "1          6        60          60       1.000000            1.0   \n",
      "2          2        68          76       0.882353            1.0   \n",
      "3          6       258         312       0.790698            1.0   \n",
      "4          7        77          77       1.000000            1.0   \n",
      "\n",
      "   cell_precision  wrc_global   wrc_avg  cer_global   cer_avg  \n",
      "0        0.863636    0.542683  0.399586    0.824219  1.081635  \n",
      "1        1.000000    0.322368  0.231944    0.848951  1.116280  \n",
      "2        0.882353    0.000000  0.069853    1.212575  3.193723  \n",
      "3        0.790698    0.474438  0.349336    0.822248  0.976642  \n",
      "4        1.000000    0.569767  0.357143    0.847458  1.091991  \n"
     ]
    }
   ],
   "source": [
    "# --- Paths ---\n",
    "image_dir = Path(\"..\\\\data\\\\regions\\\\table\")               # carpeta con imágenes\n",
    "gt_path = Path(\"..\\\\data\\\\annotations\\\\ocr_table_labels.json\")      # ground truth PubTabNet-style\n",
    "\n",
    "# --- Cargar GT en un diccionario: filename -> objeto completo ---\n",
    "gt_map = {}\n",
    "with gt_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        filename = obj.get(\"filename\")\n",
    "        if filename:\n",
    "            gt_map[filename] = obj\n",
    "\n",
    "# --- Iterar imágenes ---\n",
    "rows_out = []\n",
    "exts = {\".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "for img_path in sorted(image_dir.iterdir()):\n",
    "    if img_path.suffix.lower() not in exts:\n",
    "        continue\n",
    "\n",
    "    filename = img_path.name\n",
    "    gt = gt_map.get(filename)\n",
    "    if gt is None:\n",
    "        print(f\"⚠️ No GT para {filename}, se saltea\")\n",
    "        continue\n",
    "\n",
    "    # --- Tamaño de la imagen ---\n",
    "    # --- Tamaño original con PIL ---\n",
    "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "    orig_w, orig_h = img_pil.size\n",
    "\n",
    "    # --- Convertir a numpy (para usar cv2) ---\n",
    "    img_np = np.array(img_pil)\n",
    "\n",
    "    # --- Escalar con cv2 ---\n",
    "    img_np = cv2.resize(\n",
    "        img_np,\n",
    "        (orig_w * 2, orig_h * 2),\n",
    "        interpolation=cv2.INTER_CUBIC   # o cv2.INTER_LANCZOS4 para más calidad\n",
    "    )\n",
    "\n",
    "    # --- Volver a PIL para usar con TATR ---\n",
    "    img = Image.fromarray(img_np)\n",
    "\n",
    "    # --- Nuevo tamaño ---\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    # --- Conteos reales (GT) ---\n",
    "    gt_counts = count_structure_from_pubtabnet(gt)\n",
    "    gt_cells = reconstruct_gt_cells(gt)\n",
    "\n",
    "    # --- Conteos predichos y textos ---\n",
    "    # acá usás tu pipeline para obtener pack[\"grid\"]\n",
    "    # 1) Aplico el modelo de TATR a la imagen\n",
    "    structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "        \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "    ).to(device)\n",
    "\n",
    "    structure_transform = transforms.Compose([\n",
    "        MaxResize(1000),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    pixel_values = structure_transform(img).unsqueeze(0)\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = structure_model(pixel_values)\n",
    "    \n",
    "    # 2) Paso los datos crudos del tatr a lo legible\n",
    "    structure_id2label = structure_model.config.id2label\n",
    "    structure_id2label[len(structure_id2label)] = \"no object\"\n",
    "    cells = outputs_to_objects(outputs, img.size, structure_id2label)\n",
    "    \n",
    "    # 3) Construir grilla con merges de spans\n",
    "    pack = build_grid_with_spans(cells)\n",
    "\n",
    "    # 4) Completar OCR por celda (sobre la imagen original)\n",
    "    pack = fill_grid_with_ocr(\n",
    "        grid_pack=pack,\n",
    "        image_path=\"tabla.jpg\",           # ruta a la misma imagen usada para el modelo\n",
    "        tess_cfg=\"--oem 3 --psm 6\",       # ajustá PSM si hace falta\n",
    "        skip_headers=False,               # poné True si querés saltear headers\n",
    "    )\n",
    "    grid = pack[\"grid\"]\n",
    "\n",
    "    pred_rows = []\n",
    "    for r in range(pack[\"n_rows\"]):\n",
    "        row_texts = [cell[\"text\"] for cell in grid[r] if not cell[\"covered\"]]\n",
    "        pred_rows.append(row_texts)\n",
    "\n",
    "    pred_cells = flatten_pred_rows(pred_rows)\n",
    "    pred_counts = {\n",
    "        \"rows\": pack[\"n_rows\"],\n",
    "        \"cols\": pack[\"n_cols\"],\n",
    "        \"cells\": pack[\"cells_counted\"],  # asumimos que tu pack trae esto\n",
    "    }\n",
    "\n",
    "    # --- Precisiones estructurales ---\n",
    "    comp = structure_precision_counts(pred_counts, gt_counts)\n",
    "\n",
    "    # --- Métricas WRC y CER ---\n",
    "    wrc_g = wrc_global(gt_cells, pred_cells)\n",
    "    wrc_c = wrc_cellwise(gt_cells, pred_cells)\n",
    "    cer_g = cer_global(gt_cells, pred_cells)\n",
    "    cer_c = cer_cellwise(gt_cells, pred_cells)\n",
    "\n",
    "    # --- Registrar resultados ---\n",
    "    rows_out.append({\n",
    "        \"filename\": filename,\n",
    "        \"img_w\": img_w,\n",
    "        \"img_h\": img_h,\n",
    "        \"gt_rows\": gt_counts[\"rows\"],\n",
    "        \"pred_rows\": pred_counts[\"rows\"],\n",
    "        \"gt_cols\": gt_counts[\"cols\"],\n",
    "        \"pred_cols\": pred_counts[\"cols\"],\n",
    "        \"gt_cells\": gt_counts[\"cells\"],\n",
    "        \"pred_cells\": pred_counts[\"cells\"],\n",
    "        \"row_precision\": comp[\"rows\"][\"precision\"],\n",
    "        \"col_precision\": comp[\"cols\"][\"precision\"],\n",
    "        \"cell_precision\": comp[\"cells\"][\"precision\"],\n",
    "        \"wrc_global\": wrc_g,\n",
    "        \"wrc_avg\": wrc_c,\n",
    "        \"cer_global\": cer_g,\n",
    "        \"cer_avg\": cer_c,\n",
    "    })\n",
    "\n",
    "# --- DataFrame final ---\n",
    "df_results_1 = pd.DataFrame(rows_out)\n",
    "df_results_1.to_csv(\"metrics_results_1.csv\", index=False)\n",
    "print(df_results_1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c948a98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_w             780.720000\n",
      "img_h             443.020000\n",
      "gt_rows            15.480000\n",
      "pred_rows          15.820000\n",
      "gt_cols             4.830000\n",
      "pred_cols           4.890000\n",
      "gt_cells           65.870000\n",
      "pred_cells         72.980000\n",
      "row_precision       0.965003\n",
      "col_precision       0.980726\n",
      "cell_precision      0.902942\n",
      "wrc_global          0.655685\n",
      "wrc_avg             0.293468\n",
      "cer_global          0.851446\n",
      "cer_avg             1.597833\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# mean de todas las columnas numéricas\n",
    "df_mean = df_results_1.mean(numeric_only=True)\n",
    "\n",
    "print(df_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb510526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TesisOCR_TATR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
