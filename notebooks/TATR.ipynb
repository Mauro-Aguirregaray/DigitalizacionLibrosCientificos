{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c122e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ruta absoluta a la carpeta src\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from utils_TATR import outputs_to_objects, build_grid_with_spans, fill_grid_with_ocr, fill_grid_from_global_ocr_centered, draw_tatr_overlays_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702e32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "from torchvision import transforms  # üëà aqu√≠ est√° 'transforms'\n",
    "\n",
    "#from tatr_ocr.transforms_tatr import make_structure_transform, to_model_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a65a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "cropped_table = Image.open(\"../temp/Tabla.png\").convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714d4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MaxResize:\n",
    "    \"\"\"\n",
    "    Redimensiona una imagen manteniendo aspecto para que el lado mayor sea `max_size`.\n",
    "    A diferencia de la versi√≥n \"segura\", esta implementaci√≥n **tambi√©n hace upscaling**\n",
    "    si la imagen es m√°s chica que `max_size`.\n",
    "\n",
    "    Args:\n",
    "        max_size (int): Tama√±o m√°ximo del lado mayor (la imagen resultante siempre tendr√°\n",
    "            su lado mayor igual a este valor).\n",
    "        resample (int): Filtro de remuestreo de PIL (por defecto Image.BILINEAR).\n",
    "\n",
    "    Returns:\n",
    "        Image.Image: Imagen redimensionada con el nuevo tama√±o.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: Si la entrada no es una instancia de PIL.Image.Image.\n",
    "        ValueError: Si la imagen tiene dimensiones inv√°lidas (<= 0).\n",
    "\n",
    "    Examples:\n",
    "        >>> img = Image.open(\"ejemplo.jpg\")\n",
    "        >>> transform = MaxResize(max_size=800)\n",
    "        >>> out = transform(img)\n",
    "        >>> out.size\n",
    "        (800, 533)  # si la original era 1200x800\n",
    "    \"\"\"\n",
    "    max_size: int = 800\n",
    "    resample: int = Image.BILINEAR\n",
    "\n",
    "    def __call__(self, image: Image.Image) -> Image.Image:\n",
    "        if not isinstance(image, Image.Image):\n",
    "            raise TypeError(f\"Se esperaba PIL.Image.Image, recibido: {type(image)}\")\n",
    "\n",
    "        width, height = image.size\n",
    "        if width <= 0 or height <= 0:\n",
    "            raise ValueError(f\"Tama√±o de imagen inv√°lido: {image.size}\")\n",
    "\n",
    "        current_max = max(width, height)\n",
    "        scale = self.max_size / float(current_max)\n",
    "        new_w = max(1, int(round(scale * width)))\n",
    "        new_h = max(1, int(round(scale * height)))\n",
    "\n",
    "        return image.resize((new_w, new_h), resample=self.resample)\n",
    "\n",
    "\n",
    "def make_structure_transform(\n",
    "    max_size: int = 1000,\n",
    "    mean: Sequence[float] = (0.485, 0.456, 0.406),\n",
    "    std: Sequence[float] = (0.229, 0.224, 0.225),\n",
    "):\n",
    "    \"\"\"\n",
    "    Construye un pipeline `transforms.Compose` para preparar im√°genes de estructura/tablas.\n",
    "\n",
    "    El pipeline incluye:\n",
    "    - MaxResize: asegura que el lado mayor quede exactamente en `max_size`.\n",
    "    - ToTensor: convierte a tensor (C,H,W) en [0,1].\n",
    "    - Normalize: normaliza con `mean` y `std` (por defecto, ImageNet).\n",
    "\n",
    "    Args:\n",
    "        max_size (int): Tama√±o m√°ximo del lado mayor tras redimensionar.\n",
    "        mean (Sequence[float]): Medias para normalizaci√≥n.\n",
    "        std (Sequence[float]): Desv√≠os est√°ndar para normalizaci√≥n.\n",
    "\n",
    "    Returns:\n",
    "        transforms.Compose: Transformaci√≥n compuesta lista para usar.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: Si torchvision no est√° disponible en el entorno.\n",
    "    \"\"\"\n",
    "    if transforms is None:\n",
    "        raise RuntimeError(\"torchvision no est√° disponible en el entorno.\")\n",
    "\n",
    "    return transforms.Compose([\n",
    "        MaxResize(max_size=max_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94dba2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# cargar modelo en el notebook\n",
    "structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "    \"microsoft/table-structure-recognition-v1.1-all\"\n",
    ").to(device)\n",
    "\n",
    "structure_transform = transforms.Compose([\n",
    "    MaxResize(1000),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a24379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 817, 1000])\n"
     ]
    }
   ],
   "source": [
    "pixel_values = structure_transform(cropped_table).unsqueeze(0)\n",
    "pixel_values = pixel_values.to(device)\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82368c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "with torch.no_grad():\n",
    "  outputs = structure_model(pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d07bb3",
   "metadata": {},
   "source": [
    "id2label me tira con las opciones que me puede dar la tabla que son:\n",
    "\n",
    "* table\n",
    "* table header\n",
    "* etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561fd8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'table column', 'score': 0.999760091304779, 'bbox': [155.16644287109375, 8.200841903686523, 304.0018005371094, 324.7685546875]}, {'label': 'table projected row header', 'score': 0.9993738532066345, 'bbox': [10.024808883666992, 181.23484802246094, 393.9793701171875, 204.9191131591797]}, {'label': 'table row', 'score': 0.9996801614761353, 'bbox': [10.172329902648926, 76.26949310302734, 393.9169616699219, 96.2672348022461]}, {'label': 'table projected row header', 'score': 0.9960764050483704, 'bbox': [9.866539001464844, 32.31974792480469, 394.02288818359375, 55.840484619140625]}, {'label': 'table row', 'score': 0.9988014698028564, 'bbox': [10.10543155670166, 32.47331619262695, 393.9928283691406, 56.07625198364258]}, {'label': 'table column', 'score': 0.9998887777328491, 'bbox': [305.11614990234375, 8.225656509399414, 394.08612060546875, 324.76007080078125]}, {'label': 'table row', 'score': 0.9993184804916382, 'bbox': [10.132570266723633, 181.26565551757812, 394.0206298828125, 204.8665771484375]}, {'label': 'table column header', 'score': 0.9993597865104675, 'bbox': [10.068622589111328, 8.152742385864258, 394.071533203125, 32.30127716064453]}, {'label': 'table row', 'score': 0.9994421601295471, 'bbox': [10.129247665405273, 55.91062927246094, 393.931396484375, 76.0816421508789]}, {'label': 'table row', 'score': 0.9996668100357056, 'bbox': [10.098302841186523, 284.93060302734375, 393.9993896484375, 304.84893798828125]}, {'label': 'table row', 'score': 0.9997945427894592, 'bbox': [10.198439598083496, 244.77023315429688, 394.0396728515625, 264.800537109375]}, {'label': 'table', 'score': 0.9999728202819824, 'bbox': [10.06103515625, 8.156368255615234, 393.8989562988281, 324.7347717285156]}, {'label': 'table row', 'score': 0.999579131603241, 'bbox': [10.114023208618164, 155.83766174316406, 393.8977966308594, 180.97044372558594]}, {'label': 'table row', 'score': 0.9997771382331848, 'bbox': [10.148786544799805, 224.8220672607422, 394.01702880859375, 244.90330505371094]}, {'label': 'table row', 'score': 0.999701201915741, 'bbox': [10.206746101379395, 96.27086639404297, 393.91363525390625, 116.40066528320312]}, {'label': 'table row', 'score': 0.9996242523193359, 'bbox': [10.078987121582031, 304.9075012207031, 393.9684753417969, 324.7740173339844]}, {'label': 'table row', 'score': 0.9996662139892578, 'bbox': [10.150410652160645, 116.45174407958984, 393.89276123046875, 136.412109375]}, {'label': 'table row', 'score': 0.9996459484100342, 'bbox': [10.110365867614746, 136.20382690429688, 393.92041015625, 156.3773956298828]}, {'label': 'table column', 'score': 0.999586284160614, 'bbox': [10.201799392700195, 8.17626953125, 154.6082000732422, 324.7006530761719]}, {'label': 'table row', 'score': 0.9996864795684814, 'bbox': [10.255146980285645, 204.80345153808594, 393.90966796875, 224.98477172851562]}, {'label': 'table row', 'score': 0.9998519420623779, 'bbox': [10.002604484558105, 8.129201889038086, 394.1058349609375, 32.32856750488281]}, {'label': 'table row', 'score': 0.9998067021369934, 'bbox': [10.237529754638672, 264.7756652832031, 393.9872131347656, 284.9497985839844]}]\n"
     ]
    }
   ],
   "source": [
    "# arm√°s el id2label seg√∫n tu proyecto\n",
    "structure_id2label = structure_model.config.id2label\n",
    "structure_id2label[len(structure_id2label)] = \"no object\"\n",
    "# si en tu caso no hace falta \"no object\", no lo agreg√°s\n",
    "\n",
    "cells = outputs_to_objects(outputs, cropped_table.size, structure_id2label)\n",
    "\n",
    "print(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d888c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: ['Tipo de estructura', 'Cantidad total', '‚Äî_Porcentaje']\n",
      "Row 1: ['Instancias del total del dataset de Publaynet']\n",
      "Row 2: ['Texto', '2.376.702', '71,76 %']\n",
      "Row 3: ['Titulo', '633.359', '19,12 %']\n",
      "Row 4: ['Lista', '81.850', '% 247']\n",
      "Row 5: ['Tabla', '103.057', '3,11%']\n",
      "Row 6: ['Figura', '116.692', '3,52 %']\n",
      "Row 7: ['Total de instancias', '3,311,660', '100%']\n",
      "Row 8: ['Recortes extraidos de aleatoria 100 paginas muestra una']\n",
      "Row 9: ['Figura', '2', '2,14%']\n",
      "Row 10: ['Lista', '25', '243%']\n",
      "Row 11: ['Tabla', '32', '312%']\n",
      "Row 12: ['Titulo', '181', '% 17,63']\n",
      "Row 13: ['Texto', '767', '74,68¬∞%']\n",
      "Row 14: ['Total de recortes', '1.027', '100%']\n"
     ]
    }
   ],
   "source": [
    "# 3) Armar grilla (con spans/headers)\n",
    "pack = build_grid_with_spans(cells, iou_th=0.6, overlap_th=0.5)\n",
    "\n",
    "# 4) OCR global ‚Üí asignaci√≥n por centro\n",
    "pack = fill_grid_from_global_ocr_centered(\n",
    "    grid_pack=pack,\n",
    "    image_path=\"../temp/Tabla.png\",\n",
    "    tess_cfg=\"--oem 3 --psm 6\",\n",
    "    min_conf=0,          # sub√≠ si hay ruido (por ej., 40-60)\n",
    "    joiner=\" \",\n",
    "    skip_headers=False,\n",
    ")\n",
    "\n",
    "# 5) Visualizar en Colab/Jupyter\n",
    "# 5) Ejemplo: recorrer la grilla\n",
    "grid = pack[\"grid\"]\n",
    "for r in range(pack[\"n_rows\"]):\n",
    "    row_texts = [cell[\"text\"] for cell in grid[r] if not cell[\"covered\"]]\n",
    "    print(f\"Row {r}: {row_texts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39e60c",
   "metadata": {},
   "source": [
    "## Visualizaci√≥n de imagenes por tipo (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdfa08e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im√°genes generadas:\n",
      "table: ../temp\\tatr_table.png\n",
      "table_column_header: ../temp\\tatr_table_column_header.png\n",
      "table_row_header: ../temp\\tatr_table_row_header.png\n",
      "table_projected_row_header: ../temp\\tatr_table_projected_row_header.png\n",
      "table_row: ../temp\\tatr_table_row.png\n",
      "table_column: ../temp\\tatr_table_column.png\n",
      "table_spanning_cell: ../temp\\tatr_table_spanning_cell.png\n",
      "all: ../temp\\tatr_all.png\n"
     ]
    }
   ],
   "source": [
    "from utils_TATR import draw_tatr_overlays_multi\n",
    "\n",
    "# detections es la lista de dicts que obtuviste con outputs_to_objects(...)\n",
    "detections = cells  \n",
    "\n",
    "# ruta de la imagen original que procesaste con el modelo\n",
    "image_path = \"../temp/Tabla.png\"\n",
    "\n",
    "# carpeta de salida (ej: \"../temp\" si est√° fuera de notebooks/)\n",
    "out_dir = \"../temp\"\n",
    "\n",
    "# generar las im√°genes con overlays\n",
    "paths = draw_tatr_overlays_multi(\n",
    "    image_path=image_path,\n",
    "    detections=detections,\n",
    "    out_dir=out_dir,\n",
    "    alpha=0.3,       # transparencia (0=sin relleno, 1=totalmente opaco)\n",
    "    thickness=2,     # grosor de los bordes\n",
    "    put_labels=True  # si mostrar etiquetas de clase y score\n",
    ")\n",
    "\n",
    "print(\"Im√°genes generadas:\")\n",
    "for k, v in paths.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea39762",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Se van a sacar las siguientes estad√≠sticas para el estudio de 100 im√°genes random del dataset de pubtabnet:\n",
    "\n",
    "* Tama√±o de la imagen\n",
    "* Cantidad de filas reales\n",
    "* Cantidad de filas predichas\n",
    "* Cantidad de columnas reales\n",
    "* Cantidad de columnas predichas\n",
    "* Cantidad de celdas reales\n",
    "* Cantidad de celdas predichas\n",
    "* Row Precision\n",
    "* Column Precision\n",
    "* Cell Precision\n",
    "* WRC Global\n",
    "* WCC Global\n",
    "* CER Promedio\n",
    "* CER Global\n",
    "\n",
    "$\\text{precision} = 1 - \\dfrac{|\\text{pred} - \\text{gt}|}{\\text{gt}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2a2f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27dbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para tratar con el ground truth en formato json\n",
    "from typing import Dict, Literal, Any, List\n",
    "from jiwer import cer\n",
    "\n",
    "def count_structure_from_pubtabnet(gt: Dict) -> Dict[str, int]:\n",
    "    \"\"\"Cuenta rows, cols y cells usando html.structure.tokens de PubTabNet-like.\n",
    "\n",
    "    Reglas:\n",
    "    - rows: cantidad de <tr>\n",
    "    - cols: m√°ximo n¬∫ de celdas por fila (cuenta <td> y <th> entre <tr> ... </tr>)\n",
    "    - cells: total de celdas (<td> + <th>) en toda la tabla\n",
    "\n",
    "    Args:\n",
    "        gt: dict con clave 'html' -> {'structure': {'tokens': [...]}}.\n",
    "\n",
    "    Returns:\n",
    "        {'rows': int, 'cols': int, 'cells': int}\n",
    "    \"\"\"\n",
    "    tokens: List[str] = gt[\"html\"][\"structure\"][\"tokens\"]\n",
    "    rows = 0\n",
    "    max_cols = 0\n",
    "    total_cells = 0\n",
    "\n",
    "    in_row = False\n",
    "    cells_in_current_row = 0\n",
    "\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        tok = tokens[i]\n",
    "\n",
    "        if tok == \"<tr>\":\n",
    "            # cerrar fila previa si qued√≥ abierta (por robustez)\n",
    "            if in_row:\n",
    "                rows += 1\n",
    "                max_cols = max(max_cols, cells_in_current_row)\n",
    "                cells_in_current_row = 0\n",
    "            in_row = True\n",
    "\n",
    "        elif tok in (\"</tr>\",):\n",
    "            if in_row:\n",
    "                rows += 1\n",
    "                max_cols = max(max_cols, cells_in_current_row)\n",
    "                cells_in_current_row = 0\n",
    "                in_row = False\n",
    "\n",
    "        elif tok in (\"<td>\", \"<th>\"):\n",
    "            total_cells += 1\n",
    "            if in_row:\n",
    "                cells_in_current_row += 1\n",
    "\n",
    "        # ignoramos otros tokens (<thead>, </thead>, <tbody>, </tbody>, </td>, </th>, etc.)\n",
    "        i += 1\n",
    "\n",
    "    # si termin√≥ el stream con una fila abierta (sin </tr>)\n",
    "    if in_row:\n",
    "        rows += 1\n",
    "        max_cols = max(max_cols, cells_in_current_row)\n",
    "\n",
    "    return {\"rows\": rows, \"cols\": max_cols, \"cells\": total_cells}\n",
    "\n",
    "def structure_precision_counts(\n",
    "    pred_stats: Dict[str, int],\n",
    "    gt_stats: Dict[str, int],\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Compara conteos de estructura (rows/cols/cells) entre pred y GT y calcula precisi√≥n.\n",
    "\n",
    "    La m√©trica se define como:\n",
    "        precision = 1 - |pred - gt| / gt\n",
    "\n",
    "    Args:\n",
    "        pred_stats: {'rows': int, 'cols': int, 'cells': int} predichos.\n",
    "        gt_stats:   {'rows': int, 'cols': int, 'cells': int} ground truth.\n",
    "\n",
    "    Returns:\n",
    "        Dict con claves 'rows', 'cols', 'cells'. Cada una contiene:\n",
    "            - gt: int\n",
    "            - pred: int\n",
    "            - delta: int (pred - gt)\n",
    "            - precision: float entre 0 y 1\n",
    "    \"\"\"\n",
    "    out: Dict[str, Dict[str, float]] = {}\n",
    "    for key in (\"rows\", \"cols\", \"cells\"):\n",
    "        gt_val = int(gt_stats.get(key, 0))\n",
    "        pred_val = int(pred_stats.get(key, 0))\n",
    "        delta = pred_val - gt_val\n",
    "\n",
    "        if gt_val == 0:\n",
    "            # si el GT no tiene valor, definimos precision = 1 si pred==0, si no 0\n",
    "            precision = 1.0 if pred_val == 0 else 0.0\n",
    "        else:\n",
    "            precision = 1 - abs(delta) / gt_val\n",
    "            precision = max(0.0, min(1.0, precision))  # clamp a [0,1]\n",
    "\n",
    "        out[key] = {\n",
    "            \"gt\": gt_val,\n",
    "            \"pred\": pred_val,\n",
    "            \"delta\": delta,\n",
    "            \"precision\": precision,\n",
    "        }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d9d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_words_from_pubtabnet(gt: Dict[str, Any]) -> int:\n",
    "    \"\"\"Reconstruye texto de celdas y cuenta palabras en todo el GT.\n",
    "\n",
    "    Args:\n",
    "        gt: dict con clave 'html' -> {'cells': [{'tokens': [...]}]}.\n",
    "\n",
    "    Returns:\n",
    "        N√∫mero total de palabras.\n",
    "    \"\"\"\n",
    "    total_words = 0\n",
    "    for cell in gt[\"html\"][\"cells\"]:\n",
    "        tokens = cell.get(\"tokens\", [])\n",
    "        # unir tokens en un string completo\n",
    "        text = \"\".join(\n",
    "            t for t in tokens \n",
    "            if not (t.startswith(\"<\") and t.endswith(\">\"))  # descartar tags\n",
    "        )\n",
    "        # dividir por espacios\n",
    "        words = [w for w in text.split(\" \") if w.strip()]\n",
    "        total_words += len(words)\n",
    "    return total_words\n",
    "\n",
    "def reconstruct_gt_cells(gt: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Reconstruye el texto de cada celda en GT PubTabNet.\"\"\"\n",
    "    cells = []\n",
    "    for cell in gt[\"html\"][\"cells\"]:\n",
    "        tokens = cell.get(\"tokens\", [])\n",
    "        text = \"\".join(t for t in tokens if not (t.startswith(\"<\") and t.endswith(\">\")))\n",
    "        text = \" \".join(text.split())  # normalizar espacios\n",
    "        cells.append(text)\n",
    "    return cells\n",
    "\n",
    "def flatten_pred_rows(pred_rows: List[List[str]]) -> List[str]:\n",
    "    \"\"\"Convierte predicci√≥n en lista plana de celdas.\"\"\"\n",
    "    return [c.strip() for row in pred_rows for c in row]\n",
    "\n",
    "def wrc_single(n_gt: int, n_pred: int) -> float:\n",
    "    \"\"\"Word Rate Count para un par de conteos.\"\"\"\n",
    "    if n_gt == 0:\n",
    "        return 1.0 if n_pred == 0 else 0.0\n",
    "    wrc = 1 - abs(n_pred - n_gt) / n_gt\n",
    "    return max(0.0, min(1.0, wrc))\n",
    "\n",
    "def wrc_global(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"WRC considerando todas las palabras de la tabla.\"\"\"\n",
    "    n_gt = sum(len(c.split()) for c in gt_cells)\n",
    "    n_pred = sum(len(c.split()) for c in pred_cells)\n",
    "    return wrc_single(n_gt, n_pred)\n",
    "\n",
    "def wrc_cellwise(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"WRC promedio celda a celda.\"\"\"\n",
    "    n = len(gt_cells)\n",
    "    if n == 0:\n",
    "        return 1.0\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        gt_text = gt_cells[i] if i < len(gt_cells) else \"\"\n",
    "        pred_text = pred_cells[i] if i < len(pred_cells) else \"\"\n",
    "        scores.append(wrc_single(len(gt_text.split()), len(pred_text.split())))\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "def cer_pair(gt: str, pred: str) -> float:\n",
    "    \"\"\"CER entre dos textos normalizados.\"\"\"\n",
    "    gt_norm = \" \".join(gt.split())\n",
    "    pred_norm = \" \".join(pred.split())\n",
    "    if not gt_norm:\n",
    "        return 0.0 if not pred_norm else 1.0\n",
    "    return float(cer(gt_norm, pred_norm))\n",
    "\n",
    "def cer_global(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"CER considerando toda la tabla concatenada.\"\"\"\n",
    "    gt_text = \" \".join(\" \".join(c.split()) for c in gt_cells).strip()\n",
    "    pred_text = \" \".join(\" \".join(c.split()) for c in pred_cells).strip()\n",
    "    return cer_pair(gt_text, pred_text)\n",
    "\n",
    "def cer_cellwise(gt_cells: List[str], pred_cells: List[str]) -> float:\n",
    "    \"\"\"CER promedio celda a celda.\"\"\"\n",
    "    n = len(gt_cells)\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        gt_text = gt_cells[i] if i < len(gt_cells) else \"\"\n",
    "        pred_text = pred_cells[i] if i < len(pred_cells) else \"\"\n",
    "        scores.append(cer_pair(gt_text, pred_text))\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96b151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No GT para PMC1180437_003_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC1215488_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC1796903_013_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2174470_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2654114_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2679760_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2688351_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2741432_008_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2781010_008_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2837001_002_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3042936_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3103444_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3213066_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3284427_006_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3296643_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3349608_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3399222_010_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3414058_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3426469_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3442972_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3448500_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3465184_007_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3469388_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3488582_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3492817_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3543344_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3568058_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3571792_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3590442_001_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3600185_004_02.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3751346_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3791439_003_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3797049_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3851160_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3857257_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3879098_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3973997_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4048619_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4106230_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4107379_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4152582_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4216381_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4234831_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4300612_001_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4403562_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4417574_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4443755_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4573746_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4587579_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4591530_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4609470_003_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4689805_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4714460_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4730439_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4732478_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4736197_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4842305_012_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4871302_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4873504_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4880972_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4908466_006_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4980790_011_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5027634_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5028949_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5050670_005_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5111420_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5124310_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5154142_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5155125_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5159971_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5297745_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5352876_001_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5364675_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5406936_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5435261_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5448947_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5472948_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5510103_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5517789_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5597084_015_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5606674_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5620310_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5673733_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5676673_019_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5686943_001_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5706893_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5715995_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5751014_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5877327_022_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5923382_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5932779_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5952850_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5978059_016_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5980498_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5982508_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC6063011_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC6071173_002_00.png, se saltea\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 131\u001b[0m\n\u001b[0;32m    129\u001b[0m df_results_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows_out)\n\u001b[0;32m    130\u001b[0m df_results_1\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics_results_1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_results\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_results' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# --- Asumimos que ya ten√©s estas funciones definidas ---\n",
    "# count_structure_from_pubtabnet\n",
    "# structure_precision_counts\n",
    "# reconstruct_gt_cells\n",
    "# flatten_pred_rows\n",
    "# wrc_global, wrc_cellwise\n",
    "# cer_global, cer_cellwise\n",
    "\n",
    "# --- Paths ---\n",
    "image_dir = Path(\"..\\\\data\\\\regions\\\\table\")               # carpeta con im√°genes\n",
    "gt_path = Path(\"..\\\\data\\\\annotations\\\\ocr_table_labels.json\")      # ground truth PubTabNet-style\n",
    "\n",
    "# --- Cargar GT en un diccionario: filename -> objeto completo ---\n",
    "gt_map = {}\n",
    "with gt_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        filename = obj.get(\"filename\")\n",
    "        if filename:\n",
    "            gt_map[filename] = obj\n",
    "\n",
    "# --- Iterar im√°genes ---\n",
    "rows_out = []\n",
    "exts = {\".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "for img_path in sorted(image_dir.iterdir()):\n",
    "    if img_path.suffix.lower() not in exts:\n",
    "        continue\n",
    "\n",
    "    filename = img_path.name\n",
    "    gt = gt_map.get(filename)\n",
    "    if gt is None:\n",
    "        print(f\"‚ö†Ô∏è No GT para {filename}, se saltea\")\n",
    "        continue\n",
    "\n",
    "    # --- Tama√±o de la imagen ---\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    # --- Conteos reales (GT) ---\n",
    "    gt_counts = count_structure_from_pubtabnet(gt)\n",
    "    gt_cells = reconstruct_gt_cells(gt)\n",
    "\n",
    "    # --- Conteos predichos y textos ---\n",
    "    # ac√° us√°s tu pipeline para obtener pack[\"grid\"]\n",
    "    # 1) Aplico el modelo de TATR a la imagen\n",
    "    structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "        \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "    ).to(device)\n",
    "\n",
    "    structure_transform = transforms.Compose([\n",
    "        MaxResize(1000),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    pixel_values = structure_transform(img).unsqueeze(0)\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = structure_model(pixel_values)\n",
    "    \n",
    "    # 2) Paso los datos crudos del tatr a lo legible\n",
    "    structure_id2label = structure_model.config.id2label\n",
    "    structure_id2label[len(structure_id2label)] = \"no object\"\n",
    "    cells = outputs_to_objects(outputs, img.size, structure_id2label)\n",
    "    \n",
    "    # 3) Construir grilla con merges de spans\n",
    "    pack = build_grid_with_spans(cells)\n",
    "\n",
    "    # 4) Completar OCR por celda (sobre la imagen original)\n",
    "    pack = fill_grid_with_ocr(\n",
    "        grid_pack=pack,\n",
    "        image_path=img_path,           # ruta a la misma imagen usada para el modelo\n",
    "        tess_cfg=\"--oem 3 --psm 6\",       # ajust√° PSM si hace falta\n",
    "        skip_headers=False,               # pon√© True si quer√©s saltear headers\n",
    "    )\n",
    "    grid = pack[\"grid\"]\n",
    "\n",
    "    pred_rows = []\n",
    "    for r in range(pack[\"n_rows\"]):\n",
    "        row_texts = [cell[\"text\"] for cell in grid[r] if not cell[\"covered\"]]\n",
    "        pred_rows.append(row_texts)\n",
    "\n",
    "    pred_cells = flatten_pred_rows(pred_rows)\n",
    "    pred_counts = {\n",
    "        \"rows\": pack[\"n_rows\"],\n",
    "        \"cols\": pack[\"n_cols\"],\n",
    "        \"cells\": pack[\"cells_counted\"],  # asumimos que tu pack trae esto\n",
    "    }\n",
    "\n",
    "    # --- Precisiones estructurales ---\n",
    "    comp = structure_precision_counts(pred_counts, gt_counts)\n",
    "\n",
    "    # --- M√©tricas WRC y CER ---\n",
    "    wrc_g = wrc_global(gt_cells, pred_cells)\n",
    "    wrc_c = wrc_cellwise(gt_cells, pred_cells)\n",
    "    cer_g = cer_global(gt_cells, pred_cells)\n",
    "    cer_c = cer_cellwise(gt_cells, pred_cells)\n",
    "\n",
    "    # --- Registrar resultados ---\n",
    "    rows_out.append({\n",
    "        \"filename\": filename,\n",
    "        \"img_w\": img_w,\n",
    "        \"img_h\": img_h,\n",
    "        \"gt_rows\": gt_counts[\"rows\"],\n",
    "        \"pred_rows\": pred_counts[\"rows\"],\n",
    "        \"gt_cols\": gt_counts[\"cols\"],\n",
    "        \"pred_cols\": pred_counts[\"cols\"],\n",
    "        \"gt_cells\": gt_counts[\"cells\"],\n",
    "        \"pred_cells\": pred_counts[\"cells\"],\n",
    "        \"row_precision\": comp[\"rows\"][\"precision\"],\n",
    "        \"col_precision\": comp[\"cols\"][\"precision\"],\n",
    "        \"cell_precision\": comp[\"cells\"][\"precision\"],\n",
    "        \"wrc_global\": wrc_g,\n",
    "        \"wrc_avg\": wrc_c,\n",
    "        \"cer_global\": cer_g,\n",
    "        \"cer_avg\": cer_c,\n",
    "    })\n",
    "\n",
    "# --- DataFrame final ---\n",
    "df_results_1 = pd.DataFrame(rows_out)\n",
    "df_results_1.to_csv(\"metrics_results_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "378b728f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>img_w</th>\n",
       "      <th>img_h</th>\n",
       "      <th>gt_rows</th>\n",
       "      <th>pred_rows</th>\n",
       "      <th>gt_cols</th>\n",
       "      <th>pred_cols</th>\n",
       "      <th>gt_cells</th>\n",
       "      <th>pred_cells</th>\n",
       "      <th>row_precision</th>\n",
       "      <th>col_precision</th>\n",
       "      <th>cell_precision</th>\n",
       "      <th>wrc_global</th>\n",
       "      <th>wrc_avg</th>\n",
       "      <th>cer_global</th>\n",
       "      <th>cer_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC1232864_004_01.png</td>\n",
       "      <td>503</td>\n",
       "      <td>157</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.457246</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC1310919_004_00.png</td>\n",
       "      <td>344</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.852276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC1534032_004_01.png</td>\n",
       "      <td>503</td>\n",
       "      <td>373</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>0.986631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC1559691_002_00.png</td>\n",
       "      <td>503</td>\n",
       "      <td>557</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>258</td>\n",
       "      <td>300</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.554192</td>\n",
       "      <td>0.343971</td>\n",
       "      <td>0.588303</td>\n",
       "      <td>1.006165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC1570152_006_00.png</td>\n",
       "      <td>246</td>\n",
       "      <td>137</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.993644</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PMC5876629_005_00.png</td>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PMC5928814_004_01.png</td>\n",
       "      <td>243</td>\n",
       "      <td>212</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.180909</td>\n",
       "      <td>0.753233</td>\n",
       "      <td>1.195224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PMC5977059_004_00.png</td>\n",
       "      <td>502</td>\n",
       "      <td>194</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.676596</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.351866</td>\n",
       "      <td>1.439383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PMC6025574_003_00.png</td>\n",
       "      <td>404</td>\n",
       "      <td>337</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PMC6071402_003_03.png</td>\n",
       "      <td>238</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.887967</td>\n",
       "      <td>0.960895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename  img_w  img_h  gt_rows  pred_rows  gt_cols  \\\n",
       "0   PMC1232864_004_01.png    503    157       13         13        4   \n",
       "1   PMC1310919_004_00.png    344    103       10         10        6   \n",
       "2   PMC1534032_004_01.png    503    373       34         38        2   \n",
       "3   PMC1559691_002_00.png    503    557       43         50        6   \n",
       "4   PMC1570152_006_00.png    246    137       11         11        7   \n",
       "..                    ...    ...    ...      ...        ...      ...   \n",
       "95  PMC5876629_005_00.png    317    110        7          7        3   \n",
       "96  PMC5928814_004_01.png    243    212       19         18        3   \n",
       "97  PMC5977059_004_00.png    502    194       17         17        9   \n",
       "98  PMC6025574_003_00.png    404    337       27         27        7   \n",
       "99  PMC6071402_003_03.png    238    109        7          7        6   \n",
       "\n",
       "    pred_cols  gt_cells  pred_cells  row_precision  col_precision  \\\n",
       "0           4        44          51       1.000000            1.0   \n",
       "1           6        60          60       1.000000            1.0   \n",
       "2           2        68          76       0.882353            1.0   \n",
       "3           6       258         300       0.837209            1.0   \n",
       "4           7        77          77       1.000000            1.0   \n",
       "..        ...       ...         ...            ...            ...   \n",
       "95          3        17          19       1.000000            1.0   \n",
       "96          3        54          54       0.947368            1.0   \n",
       "97          9       141         153       1.000000            1.0   \n",
       "98          7       183         184       1.000000            1.0   \n",
       "99          6        42          42       1.000000            1.0   \n",
       "\n",
       "    cell_precision  wrc_global   wrc_avg  cer_global   cer_avg  \n",
       "0         0.840909    0.682927  0.457246    0.348958  0.999879  \n",
       "1         1.000000    0.171053  0.177778    0.800000  0.852276  \n",
       "2         0.882353    0.014085  0.014706    0.985030  0.986631  \n",
       "3         0.837209    0.554192  0.343971    0.588303  1.006165  \n",
       "4         1.000000    0.011628  0.012987    0.993644  1.000000  \n",
       "..             ...         ...       ...         ...       ...  \n",
       "95        0.882353    0.000000  0.000000    1.000000  1.000000  \n",
       "96        1.000000    0.274510  0.180909    0.753233  1.195224  \n",
       "97        0.914894    0.676596  0.304965    0.351866  1.439383  \n",
       "98        0.994536    0.000000  0.318919    1.000000  0.681081  \n",
       "99        1.000000    0.115385  0.071429    0.887967  0.960895  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ededd56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_w             390.360000\n",
      "img_h             221.510000\n",
      "gt_rows            15.480000\n",
      "pred_rows          15.840000\n",
      "gt_cols             4.830000\n",
      "pred_cols           4.890000\n",
      "gt_cells           65.870000\n",
      "pred_cells         72.870000\n",
      "row_precision       0.968008\n",
      "col_precision       0.980726\n",
      "cell_precision      0.906645\n",
      "wrc_global          0.308120\n",
      "wrc_avg             0.238653\n",
      "cer_global          0.730351\n",
      "cer_avg             0.952452\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# mean de todas las columnas num√©ricas\n",
    "df_mean = df_results_1.mean(numeric_only=True)\n",
    "\n",
    "print(df_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1d800",
   "metadata": {},
   "source": [
    "Mismo ejercicio pero con un scale a la tabla antes de aplicar OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0218ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No GT para PMC1180437_003_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC1215488_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC1796903_013_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2174470_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2654114_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2679760_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2688351_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2741432_008_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2781010_008_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC2837001_002_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3042936_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3103444_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3213066_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3284427_006_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3296643_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3349608_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3399222_010_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3414058_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3426469_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3442972_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3448500_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3465184_007_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3469388_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3488582_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3492817_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3543344_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3568058_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3571792_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3590442_001_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3600185_004_02.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3751346_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3791439_003_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3797049_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3851160_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3857257_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3879098_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC3973997_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4048619_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4106230_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4107379_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4152582_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4216381_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4234831_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4300612_001_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4403562_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4417574_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4443755_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4573746_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4587579_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4591530_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4609470_003_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4689805_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4714460_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4730439_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4732478_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4736197_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4842305_012_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4871302_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4873504_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4880972_007_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4908466_006_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC4980790_011_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5027634_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5028949_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5050670_005_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5111420_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5124310_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5154142_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5155125_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5159971_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5297745_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5352876_001_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5364675_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5406936_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5435261_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5448947_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5472948_004_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5510103_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5517789_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5597084_015_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5606674_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5620310_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5673733_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5676673_019_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5686943_001_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5706893_002_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5715995_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5751014_009_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5877327_022_01.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5923382_006_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5932779_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5952850_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5978059_016_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5980498_003_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC5982508_005_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC6063011_004_00.png, se saltea\n",
      "‚ö†Ô∏è No GT para PMC6071173_002_00.png, se saltea\n",
      "                filename  img_w  img_h  gt_rows  pred_rows  gt_cols  \\\n",
      "0  PMC1232864_004_01.png   1006    314       13         13        4   \n",
      "1  PMC1310919_004_00.png    688    206       10         10        6   \n",
      "2  PMC1534032_004_01.png   1006    746       34         38        2   \n",
      "3  PMC1559691_002_00.png   1006   1114       43         52        6   \n",
      "4  PMC1570152_006_00.png    492    274       11         11        7   \n",
      "\n",
      "   pred_cols  gt_cells  pred_cells  row_precision  col_precision  \\\n",
      "0          4        44          50       1.000000            1.0   \n",
      "1          6        60          60       1.000000            1.0   \n",
      "2          2        68          76       0.882353            1.0   \n",
      "3          6       258         312       0.790698            1.0   \n",
      "4          7        77          77       1.000000            1.0   \n",
      "\n",
      "   cell_precision  wrc_global   wrc_avg  cer_global   cer_avg  \n",
      "0        0.863636    0.542683  0.399586    0.824219  1.081635  \n",
      "1        1.000000    0.322368  0.231944    0.848951  1.116280  \n",
      "2        0.882353    0.000000  0.069853    1.212575  3.193723  \n",
      "3        0.790698    0.474438  0.349336    0.822248  0.976642  \n",
      "4        1.000000    0.569767  0.357143    0.847458  1.091991  \n"
     ]
    }
   ],
   "source": [
    "# --- Paths ---\n",
    "image_dir = Path(\"..\\\\data\\\\regions\\\\table\")               # carpeta con im√°genes\n",
    "gt_path = Path(\"..\\\\data\\\\annotations\\\\ocr_table_labels.json\")      # ground truth PubTabNet-style\n",
    "\n",
    "# --- Cargar GT en un diccionario: filename -> objeto completo ---\n",
    "gt_map = {}\n",
    "with gt_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        filename = obj.get(\"filename\")\n",
    "        if filename:\n",
    "            gt_map[filename] = obj\n",
    "\n",
    "# --- Iterar im√°genes ---\n",
    "rows_out = []\n",
    "exts = {\".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "for img_path in sorted(image_dir.iterdir()):\n",
    "    if img_path.suffix.lower() not in exts:\n",
    "        continue\n",
    "\n",
    "    filename = img_path.name\n",
    "    gt = gt_map.get(filename)\n",
    "    if gt is None:\n",
    "        print(f\"‚ö†Ô∏è No GT para {filename}, se saltea\")\n",
    "        continue\n",
    "\n",
    "    # --- Tama√±o de la imagen ---\n",
    "    # --- Tama√±o original con PIL ---\n",
    "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "    orig_w, orig_h = img_pil.size\n",
    "\n",
    "    # --- Convertir a numpy (para usar cv2) ---\n",
    "    img_np = np.array(img_pil)\n",
    "\n",
    "    # --- Escalar con cv2 ---\n",
    "    img_np = cv2.resize(\n",
    "        img_np,\n",
    "        (orig_w * 2, orig_h * 2),\n",
    "        interpolation=cv2.INTER_CUBIC   # o cv2.INTER_LANCZOS4 para m√°s calidad\n",
    "    )\n",
    "\n",
    "    # --- Volver a PIL para usar con TATR ---\n",
    "    img = Image.fromarray(img_np)\n",
    "\n",
    "    # --- Nuevo tama√±o ---\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    # --- Conteos reales (GT) ---\n",
    "    gt_counts = count_structure_from_pubtabnet(gt)\n",
    "    gt_cells = reconstruct_gt_cells(gt)\n",
    "\n",
    "    # --- Conteos predichos y textos ---\n",
    "    # ac√° us√°s tu pipeline para obtener pack[\"grid\"]\n",
    "    # 1) Aplico el modelo de TATR a la imagen\n",
    "    structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "        \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "    ).to(device)\n",
    "\n",
    "    structure_transform = transforms.Compose([\n",
    "        MaxResize(1000),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    pixel_values = structure_transform(img).unsqueeze(0)\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = structure_model(pixel_values)\n",
    "    \n",
    "    # 2) Paso los datos crudos del tatr a lo legible\n",
    "    structure_id2label = structure_model.config.id2label\n",
    "    structure_id2label[len(structure_id2label)] = \"no object\"\n",
    "    cells = outputs_to_objects(outputs, img.size, structure_id2label)\n",
    "    \n",
    "    # 3) Construir grilla con merges de spans\n",
    "    pack = build_grid_with_spans(cells)\n",
    "\n",
    "    # 4) Completar OCR por celda (sobre la imagen original)\n",
    "    pack = fill_grid_with_ocr(\n",
    "        grid_pack=pack,\n",
    "        image_path=\"tabla.jpg\",           # ruta a la misma imagen usada para el modelo\n",
    "        tess_cfg=\"--oem 3 --psm 6\",       # ajust√° PSM si hace falta\n",
    "        skip_headers=False,               # pon√© True si quer√©s saltear headers\n",
    "    )\n",
    "    grid = pack[\"grid\"]\n",
    "\n",
    "    pred_rows = []\n",
    "    for r in range(pack[\"n_rows\"]):\n",
    "        row_texts = [cell[\"text\"] for cell in grid[r] if not cell[\"covered\"]]\n",
    "        pred_rows.append(row_texts)\n",
    "\n",
    "    pred_cells = flatten_pred_rows(pred_rows)\n",
    "    pred_counts = {\n",
    "        \"rows\": pack[\"n_rows\"],\n",
    "        \"cols\": pack[\"n_cols\"],\n",
    "        \"cells\": pack[\"cells_counted\"],  # asumimos que tu pack trae esto\n",
    "    }\n",
    "\n",
    "    # --- Precisiones estructurales ---\n",
    "    comp = structure_precision_counts(pred_counts, gt_counts)\n",
    "\n",
    "    # --- M√©tricas WRC y CER ---\n",
    "    wrc_g = wrc_global(gt_cells, pred_cells)\n",
    "    wrc_c = wrc_cellwise(gt_cells, pred_cells)\n",
    "    cer_g = cer_global(gt_cells, pred_cells)\n",
    "    cer_c = cer_cellwise(gt_cells, pred_cells)\n",
    "\n",
    "    # --- Registrar resultados ---\n",
    "    rows_out.append({\n",
    "        \"filename\": filename,\n",
    "        \"img_w\": img_w,\n",
    "        \"img_h\": img_h,\n",
    "        \"gt_rows\": gt_counts[\"rows\"],\n",
    "        \"pred_rows\": pred_counts[\"rows\"],\n",
    "        \"gt_cols\": gt_counts[\"cols\"],\n",
    "        \"pred_cols\": pred_counts[\"cols\"],\n",
    "        \"gt_cells\": gt_counts[\"cells\"],\n",
    "        \"pred_cells\": pred_counts[\"cells\"],\n",
    "        \"row_precision\": comp[\"rows\"][\"precision\"],\n",
    "        \"col_precision\": comp[\"cols\"][\"precision\"],\n",
    "        \"cell_precision\": comp[\"cells\"][\"precision\"],\n",
    "        \"wrc_global\": wrc_g,\n",
    "        \"wrc_avg\": wrc_c,\n",
    "        \"cer_global\": cer_g,\n",
    "        \"cer_avg\": cer_c,\n",
    "    })\n",
    "\n",
    "# --- DataFrame final ---\n",
    "df_results_1 = pd.DataFrame(rows_out)\n",
    "df_results_1.to_csv(\"metrics_results_1.csv\", index=False)\n",
    "print(df_results_1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c948a98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_w             780.720000\n",
      "img_h             443.020000\n",
      "gt_rows            15.480000\n",
      "pred_rows          15.820000\n",
      "gt_cols             4.830000\n",
      "pred_cols           4.890000\n",
      "gt_cells           65.870000\n",
      "pred_cells         72.980000\n",
      "row_precision       0.965003\n",
      "col_precision       0.980726\n",
      "cell_precision      0.902942\n",
      "wrc_global          0.655685\n",
      "wrc_avg             0.293468\n",
      "cer_global          0.851446\n",
      "cer_avg             1.597833\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# mean de todas las columnas num√©ricas\n",
    "df_mean = df_results_1.mean(numeric_only=True)\n",
    "\n",
    "print(df_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb510526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
